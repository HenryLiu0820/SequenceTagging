{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from model import *\n",
    "\n",
    "START_TAG = \"<START>\"\n",
    "STOP_TAG = \"<STOP>\"\n",
    "EMBEDDING_DIM = 5\n",
    "HIDDEN_DIM = 4\n",
    "\n",
    "training_data = [(\n",
    "    \"the wall street journal reported today that apple corporation made money\".split(),\n",
    "    \"B I I I O O O B I O O\".split()\n",
    "), (\n",
    "    \"georgia tech is a university in georgia\".split(),\n",
    "    \"B I O O O O B\".split()\n",
    ")]\n",
    "\n",
    "word2idx = {}\n",
    "for sentence, tags in training_data:\n",
    "    for word in sentence:\n",
    "        if word not in word2idx:\n",
    "            word2idx[word] = len(word2idx)\n",
    "\n",
    "tag2idx = {\"B\": 0, \"I\": 1, \"O\": 2, START_TAG: 3, STOP_TAG: 4}\n",
    "\n",
    "# define the model\n",
    "model = BiLSTM_CRF(len(word2idx), EMBEDDING_DIM, HIDDEN_DIM, tag2idx, START_TAG, STOP_TAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10])\n",
      "tensor([[-0.0684, -0.3112, -0.1691,  0.3262,  0.3105],\n",
      "        [-0.0867, -0.3095, -0.2335,  0.3194,  0.4648],\n",
      "        [-0.0951, -0.4472, -0.2582,  0.2855,  0.3742],\n",
      "        [-0.1207, -0.4220, -0.2632,  0.2542,  0.4539],\n",
      "        [-0.1121, -0.4278, -0.2137,  0.3642,  0.3620],\n",
      "        [-0.0820, -0.3368, -0.1868,  0.5578,  0.3885],\n",
      "        [-0.0802, -0.3743, -0.2326,  0.4058,  0.3991],\n",
      "        [-0.1559, -0.5247, -0.2061,  0.3822,  0.3351],\n",
      "        [-0.0976, -0.3575, -0.1968,  0.3736,  0.3791],\n",
      "        [-0.0958, -0.3701, -0.1868,  0.3861,  0.3464],\n",
      "        [-0.1208, -0.4290, -0.2268,  0.4453,  0.4182]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "torch.Size([11, 5])\n",
      "tensor(11.1339, grad_fn=<AddBackward0>)\n",
      "tensor(6.4198, grad_fn=<SelectBackward0>)\n",
      "[1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "def prepare_sequence(seq, to_ix):\n",
    "    idxs = [to_ix[w] for w in seq]\n",
    "    return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "sentence, tag = training_data[0]\n",
    "sentence_in = prepare_sequence(sentence, word2idx)\n",
    "\n",
    "features = model.get_features(sentence_in)\n",
    "print(sentence_in)\n",
    "print(features)\n",
    "print(features.shape)\n",
    "alpha = model.calc_scores(features)\n",
    "print(alpha)\n",
    "path_score, best_path = model.decode(features)\n",
    "print(path_score)\n",
    "print(best_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n",
      "84\n",
      "90\n",
      "133\n",
      "140\n",
      "119\n",
      "180\n",
      "119\n",
      "210\n",
      "170\n",
      "1511\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "datadir = '/Users/henryliu/Desktop/Henry/学习/untitled folder/大三/大三下/自然语言处理/labs/project3/train.txt'\n",
    "# read txt file, return a list of sentences\n",
    "def read_txt(datadir):\n",
    "    with open(datadir, 'r') as f:\n",
    "        data = f.readlines()\n",
    "    data = [line.strip() for line in data]\n",
    "    data = [line.split() for line in data]\n",
    "    return data\n",
    "\n",
    "data = read_txt(datadir)\n",
    "for i in range(10):\n",
    "    print(len(data[i]))\n",
    "\n",
    "# get maximum length of sentences\n",
    "def get_max_length(data):\n",
    "    max_length = 0\n",
    "    for sentence in data:\n",
    "        if len(sentence) > max_length:\n",
    "            max_length = len(sentence)\n",
    "    return max_length\n",
    "\n",
    "max_length = get_max_length(data)\n",
    "print(max_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m datadir \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/Users/henryliu/Documents/GitHub/data/project3/processed_data\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[39m# load data\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m word2idx \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39;49mload(\u001b[39mopen\u001b[39;49m(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(datadir, \u001b[39m'\u001b[39;49m\u001b[39mword2idx.dat\u001b[39;49m\u001b[39m'\u001b[39;49m), \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[1;32m      9\u001b[0m \u001b[39mlen\u001b[39m(word2idx)\n",
      "\u001b[0;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "import dataloader\n",
    "import argparse\n",
    "import pickle\n",
    "\n",
    "datadir = '/Users/henryliu/Documents/GitHub/data/project3/processed_data'\n",
    "\n",
    "# load data\n",
    "word2idx = pickle.load(open(os.path.join(datadir, 'word2idx.dat'), 'rb'))\n",
    "len(word2idx)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
